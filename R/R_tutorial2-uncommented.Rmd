---
title: "R Tutorial II: Data visualization via ggplot"
author: "Sunwoo Jeong"
date: "5/26/2020"
output: html_document
---

# Acknowledgement

This tutorial is based on [Mike Frank's tutorial of Tidyverse](https://github.com/mcfrank/tidyverse-tutorial), which in turn is based on Hadley Wickham's [R for data scientists](http://r4ds.had.co.nz/). The latter resource contains extensive instructions on how to create effective visualizations of your experimental results, some of which we will cover today. Let's begin by calling in the data we will be working with (the Korean factivity/prosody data from my paper; we went over them in some detail during the lecture) and the necessary package (tidyverse, which includes ggplot2, which is commonly used for creating plots and visualizations in R).

```{r setup, include=FALSE}
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)

## The data
dat <- read.csv('veridicality-pilot-data-191127.csv')
head(dat)

## Inspect
summary(dat$complementizer)
summary(dat$prosody)
summary(dat$item)
```

Some notes on the data:

* The prosody column keeps track of the 4 prosody conditions used in the main trial:
  * p1: emedded subject focus (ES)
  * p2: embedded verb focus (EV)
  * p3: complementizer focus (C)
  * p4: main verb focus (MV)
* The complementizer column keeps track of the complementizers and embedding structures (jul1, jul2, geo1, geo2, go) used in the main trial, and the control items (labelled as `ctr' instead)

Do you see any problems that we should fix in the ways that the columns are set up and the relevant data are encoded?

```{r}
# Treat participant IDs as factors
dat$subjectID <- as.factor(dat$subjectID)

# Number of participants:
dat$subjectID %>% unique %>% length

# Rename the complementizer variables that Excel messed up
dat$complementizer <- as.character(dat$complementizer)
dat$complementizer[dat$complementizer == "2-Jul"] <- "jul2"
dat$complementizer[dat$complementizer == "1-Jul"] <- "jul1"
dat$complementizer <- as.factor(dat$complementizer)
```

<!-- ----------------------------------------------------------------------- -->
## Goals and Introduction

By the end of this tutorial, you will know:

+ How to create useful data summaries
+ How to create plots and visualizations from data sets
+ How to create plots and visualizations from data summaries

First, a review of functions, pipes, and summaries, as well as how to perform additional operations on the data set (e.g., adding/deleting columns). Using the `filter` command, create a new data frame which includes just the target trials, and among the target trials, just the ones involving the go/jul complementizers and all other prosodies than p3:

```{r}
# Create data frame for main trials/trials of interest 
dat_t <-
  dat %>%
  filter(complementizer != "ctr",
         complementizer != "geo1",
         complementizer != "geo2",
         prosody != "p3")

# Order verbs in intuitive pairs
dat_t$verbtype <- factor(dat_t$verbtype, levels= c("al","moreu", "gieok", "ggameok", "mit", "alanae"))

# Rename the prosody conditions in more intuitive ways
dat_t$prosody <- as.character(dat_t$prosody)
dat_t$prosody[dat_t$prosody == "p1"] <- "ES"
dat_t$prosody[dat_t$prosody == "p2"] <- "EV"
dat_t$prosody[dat_t$prosody == "p4"] <- "MV"
dat_t$prosody <- as.factor(dat_t$prosody)

# Save cleaned data
write.csv(dat_t, file = "veridicality-target-cleaned.csv")

```

## Summaries from data sets

Let's now review some ways of generating useful summaries for the data sets. As mentioned in tutorial 1, the combination of `summarise` and `group_by` can be very powerful!

```{r}
# Examining the effect of verb type on veridicality ratings
dat_s1 <- 
  dat_t %>%
  group_by(verbtype) %>%
  summarise(meanVer = mean(veridicality))
dat_s1

# Examining the effect of verb type and prosody on veridicality ratings
dat_s2 <- dat_t %>%
  group_by(verbtype, prosody) %>%
  summarise(meanVer = mean(veridicality))
dat_s2

# Examining the effect of verb type, prosody, and complementizer on veridicality ratings
dat_s3 <- dat_t %>%
  group_by(verbtype, prosody, complementizer) %>%
  summarise(meanVer = mean(veridicality))
dat_s3
```

Wow! Seems like this will come in handy later!

## Visualizations from data sets

What we will be working with is `ggplot2`. It is a plotting package that easily takes advantage of tidy data. ggplots have two important parts (there are of course more):

+ `aes` - the aesthetic mapping, or which data variables get mapped to which visual variables (x, y, color, symbol, etc.)
+ `geom` - the plotting objects that represent the data (points, lines, shapes, etc.)

Let's try plottng the raw veridicality data, with verb type on the x-axis, veridicality on the y-axis, and prosody represented as colors. A common `geom` object is a boxplot, so we will use that. Type `?geom_boxplot` to check what it visualizes.

## The vowel data from assignment 1

```{r}
dat_t %>%
  ggplot(aes(x = verbtype, y = veridicality, col = prosody)) + 
  geom_boxplot() 
```
We see that R is continuing to treat `veridiality` as a continous, numeric variables. Later, it might make more sense to treat them as (ordered) factors, but this will do for now. 


The plot above made use of the following aesthetic mappings: x-axis, y-axis, and colors. If you want to plot additional factors, you can also use panels (`facet_grid`), as follows:

```{r}
dat_t %>%
  ggplot(aes(x = verbtype, y = veridicality, col = prosody)) + 
  geom_boxplot() +
  facet_grid(. ~ complementizer)


dat_t %>%
  ggplot(aes(x = verbtype, y = veridicality)) + 
  geom_boxplot() +
  facet_grid(prosody ~ complementizer)
```


## Saving plots

If you want to save your plots for future use, the command to use is `ggsave()`.
Here is an example:

```{r}
# By default, saves the last plot
ggsave("dat_t.pdf")

# You can designate a variable to a particular plot, then save:
p1 <- dat_t %>%
  ggplot(aes(x = verbtype, y = veridicality, col = prosody)) + 
  geom_boxplot() 

# The full specifications of parameters
ggsave("dat_t.png", plot = p1, device = NULL, path = NULL,
  scale = 1, width = NA, height = NA, units = c("in", "cm", "mm"),
  dpi = 300, limitsize = TRUE)
```


## Visualizations from data summaries

Oftentimes, counts and mappings of raw data alone do not provide useful visualizations of experimental results. Recall that we were able to create useful summary tables of a data set using the functions `summarise` and `group_by`.


```{r}
dat_s3 <- 
  dat_t %>%
  group_by(verbtype, prosody, complementizer) %>%
  summarise(meanVer = mean(veridicality))

dat_s3
```

Let's plot the outputs of these summaries as follows:

```{r}
dat_s3 %>%
  ggplot(aes(x = prosody, y = meanVer, fill = prosody)) + 
  geom_bar(stat = "identity") +
  facet_grid(complementizer ~ verbtype) 
```



## Fine-tuning the summaries

Oftentimes, especially for bar plots, we would want to overlay error bars representing standard errors on top of mean values. We can easily create more sophisticated summary tables, using built-in functions:

```{r}
dat_s <- dat_t %>%
  group_by(verbtype, complementizer, prosody) %>%
  summarise(meanNat = mean(naturalness),
            meanVer = mean(veridicality),
            n = n(),
            # Standard deviations
            sdNat = sd(naturalness), 
            sdVer = sd(veridicality),
            # Standard errors
            seNat = sdNat/sqrt(n),
            seVer = sdVer/sqrt(n))
dat_s
```


Let's now create plots with error bars; before doing that, we will collapse different kinds of embedding structures, because they appear to be eliciting analogous results:

```{r}
# Combine jul1 and jul2 into jul
dat_t$complementizer2 <- dat_t$complementizer
dat_t$complementizer2 <- as.character(dat_t$complementizer2)
dat_t$complementizer2[dat_t$complementizer2 == "jul1"] <- "jul"
dat_t$complementizer2[dat_t$complementizer2 == "jul2"] <- "jul"
dat_t$complementizer2 <- as.factor(dat_t$complementizer2)

# Order complementizers in intuitive pairs
dat_t$complementizer2 <- factor(dat_t$complementizer2, levels= c("jul","go"))

# Re-do the summary
dat_s <- dat_t %>%
  group_by(verbtype, complementizer2, prosody) %>%
  summarise(meanNat = mean(naturalness),
            meanVer = mean(veridicality),
            n = n(),
            sdNat = sd(naturalness), 
            sdVer = sd(veridicality),
            seNat = sdNat/sqrt(n),
            seVer = sdVer/sqrt(n))
dat_s

# Plot the data with error bars
dat_s %>%
  ggplot(aes(x = prosody, y = meanVer, fill = prosody)) + 
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
                width=.2,                    # Width of the error bars
                position=position_dodge(.9)) +
  facet_grid(complementizer2 ~ verbtype)
```


## Making things pretty

The possibilities are endless! Below are a few basic settings. For ideas on color combinations, check this out: [http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/](http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/) If you are a fan of Wes Anderson movies, you can also check this out: [https://github.com/karthik/wesanderson](https://github.com/karthik/wesanderson)

```{r}
# Basic
p <- dat_s %>%
  ggplot(aes(x = prosody, y = meanVer, fill = prosody)) + 
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
                width=.2,                    # Width of the error bars
                position=position_dodge(.9)) +
  facet_grid(complementizer2 ~ verbtype) + 
  ggthemes::theme_few() + 
  ggthemes::scale_color_solarized() 

# Wes Anderson
# install.packages("wesanderson")
library(wesanderson)

p <- dat_s %>%
  ggplot(aes(x = prosody, y = meanVer, fill = prosody)) + 
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
                width=.2,                    # Width of the error bars
                position=position_dodge(.9)) +
  facet_grid(complementizer2 ~ verbtype) + 
  ggthemes::theme_few() +
  scale_fill_manual(values = wes_palette("GrandBudapest2"))

```


## Putting things together

Below are the final codes I used to create the visualizations:

```{r}
## Means for the controls that I got from conducting separate operations:
true_base <- 5.74
false_base <- 2.5

p <- dat_s %>%
  ggplot(aes(x = prosody, y = meanVer, fill = prosody)) + 
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
                width=.2,                    # Width of the error bars
                position=position_dodge(.9)) +
  facet_grid(complementizer2 ~ verbtype) +
  theme_bw() +
  theme(axis.title.y=element_text(size=14), 
        axis.title.x=element_blank()) + labs(y='Mean Veridicality Ratings') +
  scale_fill_manual(values = c("#D55E00", "#009E73", "#56B4E9")) +
  theme(legend.position="none") +
  theme(strip.text.x = element_text(size = 10), strip.text.y = element_text(size = 10)) +
  geom_hline(yintercept=true_base, linetype="dashed", 
                color = "#F0E442", size=1.2) + 
  geom_hline(yintercept=false_base, linetype="dashed", 
                color = "#999999", size=1.2)
```

## Exercise I

Include `geo` and plot the same things as above; any patterns?

```{r}
```

## Exercise II

Treat `veridicality` ratings as factors. Create bar plots that plot the proportion of times when participants chose each of the 7 options.
```{r}
```
